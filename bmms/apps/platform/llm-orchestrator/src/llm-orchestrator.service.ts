import { Injectable } from '@nestjs/common';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { mkdir, writeFile } from 'fs/promises';
import * as path from 'path';
import { z } from 'zod';
import { LlmChatResponse } from './llm-orchestrator/llm-orchestrator.interface';
import { CodeSearchService } from './service/code-search.service';
import { LlmOutputValidator } from './validators/llm-output.validator';
import { HelmIntegrationService } from './service/helm-integration.service';
import { debug } from '@bmms/common';

const LLMReplySchema = z.object({
  proposal_text: z.string(),
  changeset: z.object({
    model: z.string(),
    features: z.array(
      z.object({
        key: z.string(),
        value: z.union([z.string(), z.number(), z.boolean()]),
      }),
    ),
    impacted_services: z.array(z.string()),
  }),
  metadata: z.object({
    intent: z.string(),
    confidence: z.number(),
    risk: z.enum(['low', 'medium', 'high']),
  }),
});

type LLMReply = z.infer<typeof LLMReplySchema>;

const SYSTEM_PROMPT = `You are an expert business analyst that converts Vietnamese business model requests into JSON ChangeSet for Kubernetes deployment automation.

**BUSINESS MODELS:**
1. **Retail Model**: One-time purchase, inventory management
   - Required services: OrderService, InventoryService
   - BillingService mode: ONETIME
   - Note: 1 OrderService handles ALL retail products via database (product_id)
   
2. **Subscription Model**: Recurring payment, subscription plans
   - Required services: SubscriptionService, PromotionService
   - BillingService mode: RECURRING
   - Note: 1 SubscriptionService handles ALL subscription plans via database
   
3. **Freemium Model**: Free tier with optional paid add-ons
   - Required services: SubscriptionService (with is_free=true), PromotionService
   - BillingService mode: FREEMIUM (free base + pay for add-ons)
   - Add-ons: Extra storage, premium features, etc. (charged separately)
   - Note: Same SubscriptionService handles free users + add-on purchases
   
4. **Freemium + Add-on Model**: Free base plan with purchasable add-ons
   - Base plan: Free (no billing)
   - Add-ons: Paid features billed separately (e.g., extra storage, AI features)
   - BillingService mode: ADDON (only bill for add-ons, not base subscription)
   
5. **Multi-Model**: Support multiple models simultaneously
   - Required services: ALL of the above
   - BillingService mode: HYBRID (handle all billing types)
   - Note: SHARED SERVICE PATTERN - Each service type deploys ONCE, not per product
   - Example: 2 retail products + 1 subscription ‚Üí Still only 1 OrderService, 1 SubscriptionService

**CORE SERVICES (always needed):**
- AuthService, CustomerService, CRMOrchestratorService
- APIGatewayService
- CatalogueService (Product domain)
- BillingService, PaymentService (Finance domain)

**SERVICE MAPPING:**
- OrderService ‚Üí order-svc (namespace: order, port: 3011)
- InventoryService ‚Üí inventory-svc (namespace: order, port: 3013)
- SubscriptionService ‚Üí subscription-svc (namespace: order, port: 3012)
- PromotionService ‚Üí promotion-svc (namespace: product, port: 3009)
- CatalogueService ‚Üí catalogue-svc (namespace: product, port: 3007)
- BillingService ‚Üí billing-svc (namespace: finance, port: 3003)
- PaymentService ‚Üí payment-svc (namespace: finance, port: 3015)
- AuthService ‚Üí auth-svc (namespace: customer, port: 3000)
- CustomerService ‚Üí customer-svc (namespace: customer, port: 3001)
- CRMOrchestratorService ‚Üí crm-orchestrator (namespace: customer, port: 3002)
- APIGatewayService ‚Üí api-gateway (namespace: platform, port: 3099)

**INTENT TYPES:**
- "business_model_change": Chuy·ªÉn ƒë·ªïi t·ª´ model n√†y sang model kh√°c
- "business_model_expansion": M·ªü r·ªông ƒë·ªÉ h·ªó tr·ª£ nhi·ªÅu models
- "update": C·∫≠p nh·∫≠t config c·ªßa services hi·ªán t·∫°i
- "scale": Thay ƒë·ªïi s·ªë l∆∞·ª£ng replicas

**OUTPUT FORMAT:**
Return ONLY valid JSON in this exact format:
{
  "proposal_text": "Detailed explanation in Vietnamese about what changes are needed",
  "changeset": {
    "model": "BusinessModel|MultiBusinessModel|SubscriptionPlan|etc",
    "features": [
      {"key": "business_model", "value": "retail|subscription|freemium|multi"},
      {"key": "other_config_key", "value": "config_value"}
    ],
    "impacted_services": ["ServiceName1", "ServiceName2", ...]
  },
  "metadata": {
    "intent": "business_model_change|business_model_expansion|update|scale",
    "confidence": 0.85-0.99,
    "risk": "low|medium|high",
    "from_model": "retail|subscription|etc (if applicable)",
    "to_model": "subscription|multi|etc (if applicable)"
  }
}

**EXAMPLES:**

Example 1 - Retail to Subscription:
Input: "Chuy·ªÉn s·∫£n ph·∫©m Premium Plan sang subscription 199k/th√°ng"
Output: {
  "changeset": {
    "model": "BusinessModel",
    "features": [
      {"key": "business_model", "value": "subscription"},
      {"key": "subscription_price", "value": 199000}
    ],
    "impacted_services": ["SubscriptionService", "PromotionService", "BillingService", "PaymentService", "CatalogueService"]
  },
  "metadata": {
    "intent": "business_model_change",
    "from_model": "retail",
    "to_model": "subscription"
  }
}

Example 2 - Multi-Model with multiple products:
Input: "H·ªó tr·ª£ 2 retail products, 1 subscription, v√† 1 freemium"
Output: {
  "changeset": {
    "model": "MultiBusinessModel",
    "features": [
      {"key": "business_model", "value": "multi"},
      {"key": "supported_models", "value": "retail,subscription,freemium"},
      {"key": "retail_products_count", "value": 2},
      {"key": "subscription_plans_count", "value": 1},
      {"key": "freemium_enabled", "value": true}
    ],
    "impacted_services": ["OrderService", "InventoryService", "SubscriptionService", "PromotionService", "CatalogueService", "BillingService", "PaymentService", "APIGatewayService", "AuthService"]
  },
  "metadata": {
    "intent": "business_model_expansion",
    "to_model": "multi",
    "note": "SHARED SERVICE PATTERN: Each service in impacted_services list will be deployed ONCE (e.g., 1 OrderService handles both retail products, 1 SubscriptionService handles subscription + freemium)"
  }
}

Example 3 - Freemium with Add-ons:
Input: "T·∫°o g√≥i Freemium mi·ªÖn ph√≠ v·ªõi 3 add-on t√≠nh ph√≠: Extra Storage (50k/th√°ng), AI Assistant (100k/th√°ng), Priority Support (30k/th√°ng)"
Output: {
  "changeset": {
    "model": "FreemiumWithAddons",
    "features": [
      {"key": "business_model", "value": "freemium"},
      {"key": "base_plan_price", "value": 0},
      {"key": "addons_enabled", "value": true},
      {"key": "addon_extra_storage_price", "value": 50000},
      {"key": "addon_ai_assistant_price", "value": 100000},
      {"key": "addon_priority_support_price", "value": 30000}
    ],
    "impacted_services": ["SubscriptionService", "BillingService", "PaymentService", "CatalogueService", "AuthService"]
  },
  "metadata": {
    "intent": "business_model_change",
    "to_model": "freemium_addon",
    "billing_mode": "addon_only"
  }
}

Return ONLY the JSON, no markdown code blocks, no additional text.`;

@Injectable()
export class LlmOrchestratorService {
  [x: string]: any;
  private geminiClient: GoogleGenerativeAI;
  private useRAG = process.env.USE_RAG === 'true'; // üëà Feature flag

  constructor(
    private codeSearchService: CodeSearchService,
    private validator: LlmOutputValidator,
    private helmIntegrationService: HelmIntegrationService,
  ) {
    this.geminiClient = new GoogleGenerativeAI(
      process.env.GEMINI_API_KEY || '',
    );
  }

  async ask(
    message: string,
    tenant: string = 't-unknown',
    role: string = 'guest',
    lang: 'vi' | 'en' = 'vi',
  ): Promise<LlmChatResponse> {
     // üëá RAG: T√¨m code li√™n quan
    let codeContext = '';
    if (this.useRAG) {
      const relevantCode = await this.codeSearchService.searchRelevantCode(message, 3);
      
      if (relevantCode.length > 0) {
        codeContext = '\n\n=== RELEVANT CODE CONTEXT ===\n';
        relevantCode.forEach((code, idx) => {
          codeContext += `\n[${idx + 1}] ${code.file_path} (${code.chunk_type}${code.name ? `: ${code.name}` : ''})\n`;
          codeContext += `Score: ${code.score.toFixed(3)}\n`;
          codeContext += '```\n' + code.content.substring(0, 1000) + '\n```\n';
        });
        codeContext += '=== END CONTEXT ===\n';
      }
    }

    const content = await this.callGemini(message, tenant, role, lang, codeContext);

    // Clean code fence if present
    let cleaned = content.trim();
    if (cleaned.startsWith('```')) {
      cleaned = cleaned
        .replace(/^```[a-zA-Z]*\n?/, '')
        .replace(/```$/, '')
        .trim();
    }
    if (cleaned.endsWith('```')) {
      cleaned = cleaned
        .replace(/^```[a-zA-Z]*\n?/, '')
        .replace(/```$/, '')
        .trim();
    }

    // Write to file for debugging
    try {
      const dir = path.resolve(process.cwd(), 'llm_output');
      await mkdir(dir, { recursive: true });
      const outputPath = path.join(dir, `${Date.now()}_raw.json`);
      await writeFile(outputPath, cleaned, 'utf8');
      debug.log(`[LLM] Wrote clean JSON to: ${outputPath}`);
    } catch (err) {
      debug.error('[LLM] Failed to write output file:', err);
    }

    // Parse and validate JSON
    let parsed: unknown;
    try {
      parsed = JSON.parse(cleaned);
    } catch {
      const match = String(cleaned).match(/\{[\s\S]*\}/);
      if (!match) throw new Error('LLM did not return valid JSON');
      parsed = JSON.parse(match[0]);
    }

    const validated = LLMReplySchema.parse(parsed);

    // üëà ADD: Business logic validation
    const validationResult = this.validator.validate(validated);
    
    if (!validationResult.isValid) {
      throw new Error(
        `LLM output validation failed:\n${validationResult.errors.join('\n')}`,
      );
    }
    
    // Log warnings if any
    if (validationResult.warnings.length > 0) {
      debug.log('[LLM Validator] Warnings:', validationResult.warnings.join('; '));
    }
    
    // Log metadata
    if (validationResult.metadata) {
      debug.log('[LLM Validator] Metadata:', JSON.stringify(validationResult.metadata, null, 2));
    }

    // Convert value to string for gRPC (proto expects string)
    const response: LlmChatResponse = {
      proposal_text: validated.proposal_text,
      changeset: {
        model: validated.changeset.model,
        features: validated.changeset.features.map((f) => ({
          key: f.key,
          value: String(f.value), // Convert to string for proto
        })),
        impacted_services: validated.changeset.impacted_services,
      },
      metadata: validated.metadata,
    };

    // üöÄ AUTO-TRIGGER HELM DEPLOYMENT
    // Automatically generate changeset and trigger Helm deployment after successful LLM processing
    try {
      const autoDeployEnabled = process.env.AUTO_DEPLOY_ENABLED === 'true';
      const dryRunDefault = process.env.DEFAULT_DRY_RUN !== 'false'; // Default: true
      
      if (autoDeployEnabled || dryRunDefault) {
        // Trigger Helm deployment in background (don't wait)
        this.helmIntegrationService.triggerDeployment(response, dryRunDefault)
          .then((result) => {
            if (result.success) {
              debug.log('[LLM] Helm changeset generated:', result.changesetPath);
              if (result.deployed) {
                debug.log('[LLM] Helm deployment completed successfully');
              }
            }
          })
          .catch(err => {
            debug.error('[LLM] Failed to trigger Helm deployment:', err.message);
          });
      }
    } catch (error) {
      // Don't fail the LLM request if deployment trigger fails
      debug.error('[LLM] Error triggering Helm deployment:', error instanceof Error ? error.message : String(error));
    }

    return response;
  }

  // -------------------------------
  // Gemini (Google API)
  // -------------------------------
  private async callGemini(
    message: string,
    tenant: string,
    role: string,
    lang: string,
    codeContext: string = '',
  ): Promise<string> {
    // Use LLM_MODEL from env, default to gemini-2.0-flash-exp
    const modelName = process.env.LLM_MODEL || process.env.GEMINI_MODEL || 'gemini-2.0-flash-exp';
    
    // 1. C·∫•u h√¨nh model v·ªõi System Prompt
    const model = this.geminiClient.getGenerativeModel({
      model: modelName,
      systemInstruction: SYSTEM_PROMPT, // <-- Ch·ªâ d·∫´n h·ªá th·ªëng ƒë·∫∑t ·ªü ƒë√¢y
    });

    // 2. B·∫Øt ƒë·∫ßu chat (kh√¥ng c·∫ßn history v√¨ ƒë√¢y l√† 1 shot)
    const chat = model.startChat();

    // 3. T·∫°o n·ªôi dung c·ªßa User
     const userPrompt = `tenant_id=${tenant}; role=${role}; lang=${lang};
${codeContext}

Y√™u c·∫ßu: ${message}`;

    // 4. G·ª≠i tin nh·∫Øn c·ªßa User
    const result = await chat.sendMessage(userPrompt);

    return result.response.text() || '{}';
  }

  // -------------------------------
  // AI Chat Methods
  // -------------------------------
  
  /**
   * Generate text response for AI chat
   */
  async generateText(prompt: string, context: any[]): Promise<string> {
    try {
      return await this.callGeminiChat(prompt, context, 'You are a helpful AI assistant. Provide clear, concise, and helpful responses.');
    } catch (error) {
      debug.error('[AI Chat] Error:', error);
      return 'I apologize, but I encountered an error processing your request. Please try again.';
    }
  }

  /**
   * Generate code based on prompt
   */
  async generateCode(prompt: string, context: any[]): Promise<{ code: string; language: string; explanation: string }> {
    const codeSystemPrompt = `You are an expert programmer. Generate clean, well-documented code based on user requests. 
Always respond in JSON format:
{
  "code": "the generated code here",
  "language": "programming language (e.g., python, javascript, typescript)",
  "explanation": "brief explanation of what the code does"
}`;

    try {
      const responseText = await this.callGeminiChat(prompt, context, codeSystemPrompt);

      // Parse JSON response
      let cleaned = responseText.trim();
      if (cleaned.startsWith('```')) {
        cleaned = cleaned.replace(/^```[a-zA-Z]*\n?/, '').replace(/```$/, '').trim();
      }

      const parsed = JSON.parse(cleaned);
      return {
        code: parsed.code || '',
        language: parsed.language || 'python',
        explanation: parsed.explanation || 'Code generated successfully'
      };
    } catch (error) {
      debug.error('[Code Generation] Error:', error);
      return {
        code: '// Error generating code',
        language: 'text',
        explanation: 'Failed to generate code. Please try again with a clearer prompt.'
      };
    }
  }

  /**
   * Generic chat method for Gemini
   */
  private async callGeminiChat(prompt: string, context: any[], systemPrompt: string): Promise<string> {
    // Use LLM_MODEL from env, default to gemini-2.0-flash-exp
    const modelName = process.env.LLM_MODEL || process.env.GEMINI_MODEL || 'gemini-2.0-flash-exp';
    
    const model = this.geminiClient.getGenerativeModel({
      model: modelName,
      systemInstruction: systemPrompt,
    });

    // Build conversation history for Gemini
    const history = context.map((msg: any) => ({
      role: msg.role === 'assistant' ? 'model' : 'user',
      parts: [{ text: msg.content }]
    }));

    const chat = model.startChat({ history });
    const result = await chat.sendMessage(prompt);

    return result.response.text() || '';
  }

  // -------------------------------
  // Business Model Recommendation
  // -------------------------------
  
  /**
   * T∆∞ v·∫•n m√¥ h√¨nh kinh doanh ph√π h·ª£p d·ª±a tr√™n m√¥ t·∫£ c·ªßa ng∆∞·ªùi d√πng
   */
  async recommendBusinessModel(request: {
    business_description: string;
    target_audience?: string;
    revenue_preference?: string;
    lang?: string;
  }): Promise<{
    greeting: string;
    recommendation_intro: string;
    recommended_model: string;
    why_this_fits: string;
    how_it_works: string;
    next_steps: string[];
    alternatives_intro?: string;
    alternatives?: Array<{ model: string; brief_reason: string }>;
    closing?: string;
  }> {
    const lang = request.lang || 'vi';
    
    const systemPrompt = `B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n kinh doanh th√¢n thi·ªán v√† nhi·ªát t√¨nh. Nhi·ªám v·ª• c·ªßa b·∫°n l√† gi√∫p ng∆∞·ªùi d√πng (c√≥ th·ªÉ kh√¥ng bi·∫øt g√¨ v·ªÅ c√¥ng ngh·ªá hay m√¥ h√¨nh kinh doanh) ch·ªçn ƒë∆∞·ª£c c√°ch v·∫≠n h√†nh ph√π h·ª£p nh·∫•t.

**C√ÅCH N√ìI CHUY·ªÜN:**
- N√≥i nh∆∞ ƒëang t∆∞ v·∫•n tr·ª±c ti·∫øp cho m·ªôt ng∆∞·ªùi b·∫°n
- D√πng ng√¥n ng·ªØ ƒë∆°n gi·∫£n, tr√°nh thu·∫≠t ng·ªØ chuy√™n m√¥n  
- Gi·∫£i th√≠ch b·∫±ng v√≠ d·ª• th·ª±c t·∫ø d·ªÖ hi·ªÉu (Netflix, Shopee, ph√≤ng gym...)
- Th·ªÉ hi·ªán s·ª± quan t√¢m v√† ƒë·ªông vi√™n

**C√ÅC L·ª∞A CH·ªåN C√ì S·∫¥N:**

1. **retail** - "B√°n h√†ng truy·ªÅn th·ªëng" ‚≠ê CH·ªåN N√ÄY KHI B√ÅN S·∫¢N PH·∫®M V·∫¨T L√ù
   - Kh√°ch mua ‚Üí Thanh to√°n 1 l·∫ßn ‚Üí Nh·∫≠n h√†ng ‚Üí Xong
   - Gi·ªëng nh∆∞: Shopee, Tiki, c·ª≠a h√†ng ƒëi·ªán t·ª≠, c·ª≠a h√†ng qu·∫ßn √°o
   - PH√ô H·ª¢P V·ªöI: B√°n linh ki·ªán, thi·∫øt b·ªã, qu·∫ßn √°o, th·ª±c ph·∫©m, ƒë·ªì gia d·ª•ng, s·∫£n ph·∫©m handmade, v.v.
   - D·∫§U HI·ªÜU NH·∫¨N BI·∫æT: ng∆∞·ªùi d√πng n√≥i "b√°n", "kinh doanh", "c·ª≠a h√†ng", "s·∫£n ph·∫©m", "h√†ng h√≥a", "ship", "giao h√†ng"
   
2. **subscription** - "Thu ph√≠ ƒë·ªãnh k·ª≥" ‚≠ê CH·ªåN KHI CUNG C·∫§P D·ªäCH V·ª§ S·ªê/N·ªòI DUNG
   - Kh√°ch ƒëƒÉng k√Ω ‚Üí Tr·∫£ ti·ªÅn h√†ng th√°ng/nƒÉm ‚Üí ƒê∆∞·ª£c s·ª≠ d·ª•ng d·ªãch v·ª• LI√äN T·ª§C
   - Gi·ªëng nh∆∞: Netflix, Spotify, ph√≤ng gym, SaaS, kh√≥a h·ªçc online membership
   - PH√ô H·ª¢P V·ªöI: Streaming, ph·∫ßn m·ªÅm, n·ªôi dung s·ªë, d·ªãch v·ª• cloud, membership
   - D·∫§U HI·ªÜU NH·∫¨N BI·∫æT: "h√†ng th√°ng", "ƒë·ªãnh k·ª≥", "membership", "th√†nh vi√™n", "truy c·∫≠p kh√¥ng gi·ªõi h·∫°n"
   
3. **freemium** - "Mi·ªÖn ph√≠ c∆° b·∫£n, tr·∫£ ti·ªÅn n√¢ng c·∫•p"
   - Kh√°ch d√πng free ‚Üí Th√≠ch ‚Üí Tr·∫£ ti·ªÅn ƒë·ªÉ c√≥ th√™m t√≠nh nƒÉng
   - Gi·ªëng nh∆∞: Canva, Notion, game mobile
   - PH√ô H·ª¢P V·ªöI: ·ª®ng d·ª•ng, c√¥ng c·ª• online, game
   - D·∫§U HI·ªÜU NH·∫¨N BI·∫æT: "mi·ªÖn ph√≠", "free", "n√¢ng c·∫•p", "premium features"
   
4. **multi** - "K·∫øt h·ª£p nhi·ªÅu c√°ch"
   - V·ª´a b√°n h√†ng, v·ª´a c√≥ g√≥i membership, v·ª´a c√≥ t√≠nh nƒÉng premium
   - Gi·ªëng nh∆∞: Amazon (v·ª´a b√°n h√†ng, v·ª´a c√≥ Prime)
   - PH√ô H·ª¢P V·ªöI: Doanh nghi·ªáp l·ªõn mu·ªën ƒëa d·∫°ng h√≥a ngu·ªìn thu

**QUAN TR·ªåNG - QUY T·∫ÆC CH·ªåN:**
- N·∫øu ng∆∞·ªùi d√πng n√≥i v·ªÅ B√ÅN S·∫¢N PH·∫®M V·∫¨T L√ù (linh ki·ªán, ƒëi·ªán t·ª≠, qu·∫ßn √°o, ƒë·ªì ƒÉn, v.v.) ‚Üí LU√îN ch·ªçn **retail**
- Ch·ªâ ch·ªçn **subscription** khi h·ªç n√≥i r√µ v·ªÅ D·ªäCH V·ª§ S·ªê ho·∫∑c N·ªòI DUNG ƒë·ªãnh k·ª≥
- N·∫øu kh√¥ng ch·∫Øc ch·∫Øn v√† s·∫£n ph·∫©m l√† v·∫≠t l√Ω ‚Üí m·∫∑c ƒë·ªãnh ch·ªçn **retail**

**‚ö†Ô∏è B·∫ÆT BU·ªòC: PH·∫¢I TR·∫¢ V·ªÄ T·∫§T C·∫¢ 9 TR∆Ø·ªúNG D∆Ø·ªöI ƒê√ÇY. KH√îNG ƒê∆Ø·ª¢C B·ªé QUA TR∆Ø·ªúNG N√ÄO!**

**OUTPUT FORMAT (CH·ªà JSON, KH√îNG markdown, KH√îNG code block):**
{
  "greeting": "[B·∫ÆT BU·ªòC] L·ªùi ch√†o th√¢n thi·ªán c√≥ emoji",
  "recommendation_intro": "[B·∫ÆT BU·ªòC] Gi·ªõi thi·ªáu ng·∫Øn v·ªÅ ƒë·ªÅ xu·∫•t, VD: 'D·ª±a v√†o m√¥ t·∫£ c·ªßa b·∫°n, m√¨nh nghƒ© c√°ch ph√π h·ª£p nh·∫•t l√†:'",
  "recommended_model": "[B·∫ÆT BU·ªòC] Ch·ªâ 1 trong 4 gi√° tr·ªã: retail | subscription | freemium | multi",
  "why_this_fits": "[B·∫ÆT BU·ªòC] Gi·∫£i th√≠ch 2-3 l√Ω do T·∫†I SAO c√°ch n√†y ph√π h·ª£p v·ªõi m√¥ t·∫£ c·ªßa h·ªç",
  "how_it_works": "[B·∫ÆT BU·ªòC] Gi·∫£i th√≠ch C√ÅCH HO·∫†T ƒê·ªòNG ƒë∆°n gi·∫£n v·ªõi v√≠ d·ª• th·ª±c t·∫ø",
  "next_steps": "[B·∫ÆT BU·ªòC] M·∫£ng 3 b∆∞·ªõc ti·∫øp theo, VD: ['B·∫•m ch·ªçn m√¥ h√¨nh n√†y', 'Th√™m s·∫£n ph·∫©m', 'B·∫Øt ƒë·∫ßu b√°n']",
  "alternatives_intro": "[B·∫ÆT BU·ªòC] VD: 'N·∫øu b·∫°n ch∆∞a ch·∫Øc ch·∫Øn, ƒë√¢y l√† l·ª±a ch·ªçn kh√°c:'",
  "alternatives": "[B·∫ÆT BU·ªòC] M·∫£ng 2 l·ª±a ch·ªçn kh√°c: [{'model': '...', 'brief_reason': '1 d√≤ng m√¥ t·∫£'}]",
  "closing": "[B·∫ÆT BU·ªòC] L·ªùi k·∫øt ƒë·ªông vi√™n"
}

**V√ç D·ª§ RESPONSE HO√ÄN CH·ªàNH:**
{"greeting":"Ch√†o b·∫°n! üòä","recommendation_intro":"D·ª±a v√†o vi·ªác b·∫°n mu·ªën b√°n linh ki·ªán ƒëi·ªán t·ª≠, m√¨nh ƒë·ªÅ xu·∫•t:","recommended_model":"retail","why_this_fits":"1. Linh ki·ªán ƒëi·ªán t·ª≠ l√† s·∫£n ph·∫©m v·∫≠t l√Ω, kh√°ch mua 1 l·∫ßn v√† nh·∫≠n h√†ng. 2. Gi·ªëng nh∆∞ c√°c shop Shopee/Tiki b√°n linh ki·ªán - m√¥ h√¨nh ƒë√£ ch·ª©ng minh hi·ªáu qu·∫£. 3. D·ªÖ qu·∫£n l√Ω t·ªìn kho v√† ƒë·ªãnh gi√° theo t·ª´ng s·∫£n ph·∫©m.","how_it_works":"R·∫•t ƒë∆°n gi·∫£n: B·∫°n ƒëƒÉng linh ki·ªán l√™n ‚Üí Kh√°ch xem v√† ƒë·∫∑t mua ‚Üí Thanh to√°n ‚Üí B·∫°n giao h√†ng. Gi·ªëng nh∆∞ m·ªü shop tr√™n Shopee v·∫≠y!","next_steps":["B·∫•m ch·ªçn m√¥ h√¨nh 'B√°n h√†ng truy·ªÅn th·ªëng'","Th√™m c√°c linh ki·ªán c·ªßa b·∫°n v√†o kho","B·∫Øt ƒë·∫ßu nh·∫≠n ƒë∆°n h√†ng ƒë·∫ßu ti√™n!"],"alternatives_intro":"N·∫øu sau n√†y b·∫°n mu·ªën m·ªü r·ªông:","alternatives":[{"model":"multi","brief_reason":"K·∫øt h·ª£p th√™m g√≥i membership VIP cho kh√°ch th∆∞·ªùng xuy√™n"},{"model":"subscription","brief_reason":"N·∫øu b·∫°n c√≥ d·ªãch v·ª• s·ª≠a ch·ªØa ƒë·ªãnh k·ª≥"}],"closing":"B·∫Øt ƒë·∫ßu v·ªõi retail l√† l·ª±a ch·ªçn an to√†n nh·∫•t cho vi·ªác b√°n linh ki·ªán. Ch√∫c b·∫°n kinh doanh th√†nh c√¥ng! üöÄ"}`;

    const userPrompt = `Ng∆∞·ªùi d√πng c·∫ßn t∆∞ v·∫•n:

"${request.business_description}"
${request.target_audience ? `\nKh√°ch h√†ng h·ªç nh·∫Øm ƒë·∫øn: "${request.target_audience}"` : ''}
${request.revenue_preference ? `\nH·ªç mong mu·ªën v·ªÅ thu nh·∫≠p: "${request.revenue_preference}"` : ''}

H√£y t∆∞ v·∫•n th·∫≠t th√¢n thi·ªán, d·ªÖ hi·ªÉu b·∫±ng ${lang === 'vi' ? 'ti·∫øng Vi·ªát' : 'English'}. Gi·∫£i th√≠ch nh∆∞ ƒëang n√≥i chuy·ªán v·ªõi m·ªôt ng∆∞·ªùi b·∫°n kh√¥ng bi·∫øt g√¨ v·ªÅ kinh doanh online. Nh·ªõ tr·∫£ l·ªùi ƒë√∫ng format JSON.`;

    try {
      const responseText = await this.callGeminiChat(userPrompt, [], systemPrompt);
      
      // Log raw response from Gemini
      console.log('[Recommend Model] Raw Gemini response:', responseText);
      
      // Clean and parse response
      let cleaned = responseText.trim();
      if (cleaned.startsWith('```')) {
        cleaned = cleaned.replace(/^```[a-zA-Z]*\n?/, '').replace(/```$/, '').trim();
      }
      
      console.log('[Recommend Model] Cleaned response:', cleaned);
      
      const parsed = JSON.parse(cleaned);
      
      console.log('[Recommend Model] Parsed JSON keys:', Object.keys(parsed));
      console.log('[Recommend Model] Parsed JSON:', JSON.stringify(parsed, null, 2));
      
      const result = {
        greeting: parsed.greeting || 'Ch√†o b·∫°n! üòä',
        recommendation_intro: parsed.recommendation_intro || 'D·ª±a v√†o m√¥ t·∫£ c·ªßa b·∫°n, m√¨nh ƒë·ªÅ xu·∫•t:',
        recommended_model: parsed.recommended_model || 'retail',
        why_this_fits: parsed.why_this_fits || 'C√°ch n√†y s·∫Ω ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa b·∫°n.',
        how_it_works: parsed.how_it_works || 'Kh√°ch h√†ng s·∫Ω mua s·∫£n ph·∫©m/d·ªãch v·ª• c·ªßa b·∫°n m·ªôt c√°ch d·ªÖ d√†ng.',
        next_steps: parsed.next_steps || ['B·∫•m n√∫t b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu'],
        alternatives_intro: parsed.alternatives_intro || 'N·∫øu b·∫°n ch∆∞a ch·∫Øc, ƒë√¢y l√† m·ªôt s·ªë l·ª±a ch·ªçn kh√°c:',
        alternatives: parsed.alternatives || [],
        closing: parsed.closing || 'Ch√∫c b·∫°n kinh doanh th√†nh c√¥ng! üöÄ',
      };
      
      console.log('[Recommend Model] Final result:', JSON.stringify(result, null, 2));
      
      return result;
    } catch (error) {
      console.log('[Recommend Model] Error:', error);
      console.log('[Recommend Model] Error details:', (error as Error).message);
      return {
        greeting: 'Ch√†o b·∫°n! üòä',
        recommendation_intro: 'M√¨nh ƒë√£ xem qua m√¥ t·∫£ c·ªßa b·∫°n v√† ƒë√¢y l√† ƒë·ªÅ xu·∫•t:',
        recommended_model: 'retail',
        why_this_fits: 'Xin l·ªói, m√¨nh kh√¥ng th·ªÉ ph√¢n t√≠ch chi ti·∫øt ƒë∆∞·ª£c. Nh∆∞ng c√°ch "B√°n h√†ng truy·ªÅn th·ªëng" l√† l·ª±a ch·ªçn an to√†n v√† d·ªÖ b·∫Øt ƒë·∫ßu nh·∫•t.',
        how_it_works: 'B·∫°n ƒëƒÉng s·∫£n ph·∫©m ‚Üí Kh√°ch h√†ng xem v√† ƒë·∫∑t mua ‚Üí Thanh to√°n ‚Üí Giao h√†ng. ƒê∆°n gi·∫£n v·∫≠y th√¥i!',
        next_steps: [
          'B·∫•m n√∫t b√™n d∆∞·ªõi ƒë·ªÉ ch·ªçn c√°ch n√†y',
          'Th√™m s·∫£n ph·∫©m/d·ªãch v·ª• c·ªßa b·∫°n v√†o h·ªá th·ªëng',
          'B·∫Øt ƒë·∫ßu b√°n h√†ng!'
        ],
        closing: 'B·∫°n c√≥ th·ªÉ thay ƒë·ªïi sang c√°ch kh√°c sau n·∫øu c·∫ßn nh√©!',
      };
    }
  }
}

